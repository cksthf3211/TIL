# 큐레이팅

## 스택
- 먼저 들어 온 데이터가 나중에 나가는 형식(선입후출)
- 입구와 출구가 동일한 형태
```python
stack.append()
stack.pop()
print(stack[::-1]) # 최상단 원소부터 출력
print(stack) # 최하단 원소부터 출력
```

## 큐
- 먼저 들어 온 데이터가 먼저 나가는 형식(선입선출)
- 입구와 출구가 모두  뚫려있는 터널과 같은 형태
```python
queue.append()
queue.popleft()
print(queue) # 먼저 들어 온 순서대로 출력
queue.reverse() # 역순으로 바꾸기
print(queue) # 나중에 들어온 원소부터 출력
```

### 우선순위 큐
- 우선순위가 가장 높은 데이터를 가장 먼저 삭제하는 자료구조
- 우선순위에 따라 처리하고 싶을 때 사용
    - 가치가 높은 물건부터 꺼내서 확인할 때
- 리스트를 이용하여 구현
- 힙(Heap)을 이용하여 구현
| 우선순위 큐 구현방식 | 삽입시간  | 삭제시간  |
|  리스트                       | O(1)          | O(N)        |
|  힙                              | O(log N)   | O(log N)  |
- 힙의 특징
    - 완전 이진 트리 자료구조
    - 항상 루트 노드를 제거
    - 최소 힙
        - 루트 노드가 가장 작은 값을 가짐
        - 따라서 값이 작은 데이터가 우선적으로 제거
    - 최대 힙
        - 루트 노드가 가장 큰 값을 가짐
        - 따라서 값이 큰 데이터가 우선적으로 제거
- 완전 이진 트리
    - 루트부터 시작하여 왼쪽 자식 노드, 오른쪽 자식 노드 순으로 데이터가 차례대로 삽입되는 트리
- 최소 힙 구성 함수(Min-Heapify)
    - (상향식) 부모 노드로 거슬러 올라가며, 부모보다 값이 더 작을 경우에 위치를 교체 
    - 새로운 원소가 삽입되었을 때 O(log N)의 시간 복잡도로 힙 성질을 유지
    - 원소가 제거되었을 때 O(log N)의 시간 복잡도로 힙 성질을 유지
        - 이후 루트 노드에서부터 하향식으로 Heapify를 진행

## 트리(Tree)
- 트리는 가계도와 같은 계층적인 구조를 표현할 때 사용할 수 있는 자료구조
    - 루트 노드(root node): 부모가 없는 최상위 노드
    - 단말 노드(reaf node): 자식이 없는 노드
    - 크기(size): 트리에 포함된 모든 노드의 개수
    - 깊이(depth): 루트 노드부터의 거리
    - 높이(height): 깊이 중 최댓값
    - 차수(degree): 각 노드의(자식 방향) 간선 개수
- 기본적으로 트리의 크기가 N일 때, 전체 간선의 개수는 N - 1개

###  이진 탐색 트리(Binary Search Tree)
- 이진 탐색이 동작할 수 있도록 고안된 효율적인 탐색이 가능한 자료구조
- 특징: 왼쪽 자식 노드 < 부모 노드 < 오른쪽 자식 노드
    - 부모 노드보다 왼쪽 자식 노드가 작다.
    - 부모 노드보다 오른쪽 자식 노드가 크다.

### 트리의 순회
- 트리자료구조에 포함된 노트를 특정한 방법으로 한 번씩 방문하는 방법
    - 트리 정보를 시각적으로 확인 가능
- 트리 순회 방법
    - 전위 순회(pre-order traverse): 루트를 먼저 방문 (맨 위 시작해서 왼쪽부터 쭈르륵)
    - 중위 순회(in-order traverse): 왼쪽 자식을 방문한 뒤에 루트를 방문 (맨 왼쪽부터 오른쪽으로 쭈르륵 )
    - 후위 순회(post-order traverse): 오른쪽 자식을 방문한 뒤에 루트를 방문 (맨 왼쪽 아래부터 쭈르륵)

### 바이너리 인덱스 트리(Binary indexed Tree)
- 2진법 인덱스 구조를 활용해 구간 합 문제를 효과적으로 해결해 줄 수 있는 자료구조
- **펜윅 트리(fenwick tree)** 라고도 함
- 0이 아닌 마지막 비트를 찾는 방법
    - 특정한 숫자 K의 0이 아닌 마지막 비트를 찾기 위해서 K & -K 계산
- 트리 구조 만들기
    - -0이 아닌 마지막 비트 = 내가 저장하고 있는 값들의 개수
    - 값 변경: 0이 아닌 마지막 비트만큼 더하면서 구간 들의 값을 변경( 예시 = 3rd)
    - 누적 합(prefix sum) 구하기: 0이 아닌 마지막 비트만큼 뺴면서 구간들의 값 합 계산 (예시 = 11th )

## 정렬(sorting) 알고리즘
### 선택 정렬
- 처리되지 않은 데이터 중에서 가장 작은 데이터를 선택해 맨 앞에 있는 데이터와 바꾸는 것을 반복
- 시간 복잡도
    - N번 만큼 가장 작은 수를 찾아서 맨 앞으로 보내야함
    - 구현 방식에 따라서 오차는 있지만, 전체 연산  횟수는
        - N + (N -1) + (N - 2) + … +2
    - (N² + N - 2) / 2로 표현, O(N²)

### 삽입 정렬
- 처리되지 않은 데이터를 하나씩 골라 적절한 위치에 삽입
- 선택 정렬에 비해 구현 난이도가 높은 편이지만, 일반적으로 더 효율적으로 동작
    - 왼쪽꺼부터 쭈르륵
- 시간 복잡도
    - O(N²)이며, 선택 정렬과 마찬가지로 반복문이 두 번 중첩되어 사용.
    - 현재 리스트의 데이터가 거의 정렬되어 있는 상태라면 매우 빠르게 동작
        - 최선의 경우O(N)의 복잡도

### 퀵 정렬
- 기준 데이터를 설정하고 그 기준보다 큰 데이터와 작은 데이터의 위치를 바꾸는 방법
- 일반적인 상황에서 가장 많이 사용
- 병합 정렬과 더불어 대부분의 프로그래밍 언어의 정렬 라이브러리의 근간이 되는 알고리즘
- 가장 기본적인 퀵 정렬은 **첫 번째 데이터**(pivot)를 기준 데이터로 설정
    - 왼쪽에서부터 피벗보다 큰 데이터
    - 맨 오른쪽은 작은 다음 데이터
    - 이상적인 경우 분할이 절반씩 일어난다면 전체 연산 횟수로 O(N logN)
        - 너비 x 높이 = N x logN = N logN
    - 평균 O(N logN)의 시간 복잡도
    - 최악 O(N²)의 시간 복잡도
    - 
### 계수 정렬
- 특정한 조건이 부합할 때만 사용할 수 있지만 **매우 빠르게 동작**하는 정렬 알고리즘
     - 계수 정렬은 데이터의 크기 범위가 제한되어 정수 형태로 표현할 수 있을 떄 사용 가능
- 데이터의 개수가 N, 데이터의(양수) 중 최댓값이 K일 때 최악의 경우에도 수행 시간 O(N+K)를 보장
1. 가장 작은 데이터부터 가장 큰 데이터까지의 범위가 모두 담기는 리스트 생성
2. 데이터를 하나씩 확인하며 데이터의 값과 동일한 인덱스의 데이터 1씩 증가
3. 결과적으로 최종 리스트에는 각 데이터가 몇 번씩 등장했는지 그 횟수가 기록
4. 결과를 확인할 때는 리스트의 첫 번째 데이터부터 하나씩 그 값만큼 반복하여 인덱스 출력
- 계수 정렬의 시간 복잡도와 공간 복잡도는 모두 O(N+K)
- 계수 정렬은 때에 따라 심각한 비효율성 초래
    - 데이터가 0과 999,999로 단 2개만 존재하는 경우 생각
- 계수 정렬은 동일한 값을 가지는 데이터가 여러 개 등장할 때 효과적으로 사용
    - 성적의 경우 100점을 맞은 학생이 여러 명 일수 있끼 떄문에 계수 정렬이 효과적

### 정렬 알고리즘 비교하기
- 대부분의 프로그래밍 언어에서 지원하는 표준 정렬 라이브러리는 최악의 경우에도 O(N logN)을 보장하도록 설계

| 정렬 알고리즘  | 평균 시간 복잡도  | 공간 복잡도  | 특징                                                                                     |
| 선택 정렬         | O(N²)                    | O(N)             | 아이디어가 매우 간단하다.                                                  | 
| 삽입 정렬         | O(N²)                    | O(N)             | 데이터가 거의 정렬되어 있을 때는 가장 빠름                      | 
| 퀵 정렬             | O(N logN)            | O(N)             | 대부분의 경우에 가장 적합, 충분히 빠름                             | 
| 계수 정렬         | O(N+K)                 | O(N+K)        | 데이터의 크기가 한정되어 있는 경우에만 사용, 매우 빠름  | 

## DFS(Depth-First Search) ※코테 중요함
- DFS는 깊이 우선 탐색이라고도 부르며 그래프에서 깊은 부분을 우선적으로 탐색하는 알고리즘
- DFS는 스택 자료구조(혹은 재귀 함수)를 이용하며, 구체적인 동작 과정은
    - 탐색 시작 노드를 스택에 삽입하고 방문처리
    - 스택의 최상단 노드에 방문하지 않은 인접한 노드가 하나라도 있으면 그 노드를 스택에 넣고 방문처리. 방문하지 않은 인접 노드가 없으면 스택에서 최상단 노드를 꺼냄
    - 더 이상 2번의 과정을 수행할 수 없을 때까지 반복 

## BFS(Breadth-First Search)
- BFS는 너비 우선 탐색이라고도 부르며, 그래프에서 가까운 노드부터 우선적으로 탐색하는 알고리즘
- BFS는 큐 자료구조를 이용하며, 구체적인 동작 과정은
    - 탐색 시작 노드에 큐를 삽입하고 방문처리
    - 큐에서 노드를 꺼낸 뒤에 해당 노드의 인접 노드 중에서 방문하지 않은 노드를 모두 큐에 삽입하고 방문처리
    - 더 이상 2번의 과정을 수행할 수 없을 때까지 반복

## 최단경로 알고리즘
- 가장 짧은 경로를 찾는 알고리즘

### 다익스트라 알고리즘
- 특정한 노드에서 출발하여 다른 모든 노드로 가는 최단 경로 계산
- 음의 간선이 없을 때 정상적으로 동작
    - 현실 세계의 도로(간선)은 음의 간선으로 표현되지 않음
- 그리디 알고리즘으로 분류
    - 매 상황에서 가장 비용이 적은 노드를 선택해 임의의 과정 반복
- 매번 방문하지 않은 노드 중에서 최단 거리가 가장 짧은 노드를 선택
- 음수 간선이 없다면 최적의 해를 찾을 수 있음
- 동작 과정
    1. 출발 노드를 설정
    2. 최단 거리 테이블 초기화
    3. 방문하지 않은 노드 중에서 최단 거리가 가장 짧은 노드를 선택
    4. 해당 노드를 거쳐 다른 노드로 가는 비용을 계산하여 최단 거리 테이블 갱신
    5. 위 과정에서 3번과 4번 반복
- 성능분석
    - 힙 자료구조를 이용하는 다익스트라 알고리즘의 시간 복잡도는 O(E logN)
    - 노드를 하나씩 꺼내 검사하는 반복문은 노드의 개수 V 이상의 횟수로는 처리되지 않음
        - 결과적으로 현재 우선순위 큐에서 꺼낸 노드와 연결된 다른 노드들을 확인하는 총횟수는 최대 간선의 개수(E)만큼 연산 수행
    - 직관적으로 전체 과정은  E개의 원소를 우선순위 큐에 넣었다가 모두 빼내는 연산과 매우 유사
        - 시간 복잡도를 O(E logE)로 판단
        - 중복 간선을 포함하지 않은 경우에 이를 O(E logV)로 정리

### 플로이드 워셜 알고리즘
- 모든 노드에서 다른 모든 노드까지의 최단 경로를 모두 탐색
- 플로이드 워셜(Floyd-Warshall) 알고리즘은 다익스트라 알고리즘과 마찬가지로 단계별로 거쳐 가는 노드를 기준으로 알고리즘 수행
    - 다만 매 단계마다 방문하지 않은 노드 중에 최단 거리를 갖는 노드를 찾는 과정이 필요하지 않음
- 2차원 테이블에 최단 거리 정보를 저장
- 다이나믹 프로그래밍 유형에 속함
- 성능분석
    - 노드의 개수가 N개일 때 알고리즘상으로 N번의 단계 수행
        - 각 단계마다 O(N²)의 연산을 통해 현재 노드를 거쳐 가는 모든 경로를 고려
    - 따라서 플로이드 워셜 알고리즘의 총 시간 복잡도는 O(N³)

### 벨만 포드 알고리즘
- 매번 모든 간선을 전부 확인
    - 따라서 다익스트라 알고리즘에서의 최적의 해를 항상 포함
- 다익스트라 알고리즘에 비해서 시간이 오래 걸리짐나 음수 간선 순환을 탐지할 수 있음.

### 서로소 집합 알고리즘
- 서로소 집합(Disjoint Sets)란 공통 원소가 없는 두 집합 의미
- 서로소 부분 집합들로 나누어진 원소들의 데이터를 처리하기 위한 자료구조
- 두 종류의 연산을 지원
    - 합집합(Union): 두 개의 원소가 포함된 집합을 하나의 집합으로 합치는 연산
    - 찾기(Find): 특정한 원소가 속한 집합이 어떤 집합인지 알려주는 연산
- 서로소 집합 자료구조는 합치기 찾기(Union Find) 자료구조라고 불림
- 동작과정
    - 합집합 연산을 확인하여, 서로 연결된 두 노드 A, B를 확인
        - A와 B의 루트 노드 A', B'를 각각 찾음
        - A', B'의 부모 노드로 설정
    - 모든 합집합 연산을 처리할 때까지 1번의 과정을 반복
- 서로소 집합 자료구조에서는 연결성을 통해 손쉽게 집합의 형태를 확인

### 신장 트리 알고리즘
- 그래프에서 모든 노드를 포함하면서 사이클이 존재하지 않는 부분 그래프
    - 모든 노드가 포함되어 서로 연결되면서 사이클이 존재하지 않는다는 조건은 트리의 조건

#### 크루스칼 알고리즘
- 대표적인 최소 신장 트리 알고리즘
- 그리디 알고리즘으로 분류
- 동작 과정
    1. 간선 데이터를 비용에 따라 오름차순으로 정렬
    2. 간선을 하나씩 확인하며 현재의 간선이 사이클을 발생시키는지 확인
        1. 사이클이 발생하지 않는 경우 최소 신장 트리에 포함
        2. 사이클이 발생하는 경우 최소 신장트리에 포함 시키지 않음
    3. 모든 간선에 대하여 2번의 과정 반복
- 성능 분석
    - 간선의 개수가 E개일 때, O(E logE)의 시간 복잡도를 가짐
    - 가장 많은 시간을 요구하는 곳은 간선을 정렬 수행하는 부분
        - 표준 라이브러리를 이용해 E개의 데이터를 정렬하기 위한 시간 복잡도는 O(E logE)
### 위상 정렬
- 사이클이 없는 방향 그래프의 모든 노드를 방향성에 거스르지 않도록 순서대로 나열
- 진입차수(Indegree): 특정한 노드로 들어오는 간선의 개수
- 진출차수(Outdegree): 특정한 노드에서 나가는 간선의 개수
- 
#### 위상 정렬 알고리즘
- 동작 과정
    - 큐를 이용
    1. 진입 차수가 0인 모든 노드를 큐에 넣는다
    2. 큐가 빌 때 까지 다음의 과정 반복
        1. 큐에서 원소를 꺼내 해당 노드에서 나가는 간선을 그래프에서 제거
        2. 새롭게 진입차수가 0이 된 노드를 큐에 넣는다
- 특징
    - DAG에 대해서만 수행
        - DAG(Direct Acyclic Graph): 순환하지 않는 방향 그래프
    - 위상 정렬에서는 여러 가지 답이 존재
        - 한 단계에서 큐에 새롭게 들어가는 원소가 2개 이상인 경우가 있다면 여러 가지 답이 존재
    - 모든 원소를 방문하기 전에 큐가 빈다면 사이클이 존재한다고 판단
        - 사이클에 포함된 원소 중에서 어떠한 원소도 큐에 들어가지 못함
    - 스택을 활용한 DFS를 이용해 위상 정렬을 수행

### 에라토스테네스의 체 알고리즘
- 다수의 자연수에 대하여 소수 여부를 판별할 때 사용하는 대표적인 알고리즘
- N보다 작거나 같은 모든 소수를 찾을 때 사용
- 동작과정
    1. 2부터 N까지의 모든 자연수 나열
    2. 남은 수 중에서 아직 처리하지 않은 가장 작은 수 j를 찾는다
    3. 남은 수 중에서 i의 배수를 모두 제거한다(j제거 안함)
    4. 더 이상 반복할 수 없을 때까지 2번과 3번의 과정을 반복
- 시간 복잡도는 선형 시간에 가까울 정도로 매우 빠름
    - 시간 복잡도 O(N loglogN)
- 다수의 소수를 찾아야 하는 문제에서 효과적으로 사용

### 이진 탐색 알고리즘
- 순차탐색: 리스트 안에 있는 특정한 데이터를 찾기 위해 앞에서부터 데이터를 하나씩 확인하는 방법
- 이진탐색: 정렬되어 있는 리스트에서 탐색 범위를 절반씩 좁혀가며 데이터를 탐색하는 방법
    - 시작점, 끝점, 중간점을 이용하여 탐색 범위 설정
- 시간 복잡도
    - 단계마다 탐색 범위를 2로 나누는 것과 동일하므로 연산 횟수는 log₂N에 비례
    - 탐색 범위를 절반씩 줄이며 시간 복잡도는 O(log N)

### 그리디 알고리즘
- 현재 상황에서 지금 당장 좋은 것만 고르는 방법

### 투 포인터(Two Pointers) 알고리즘
- 리스트에 순차적으로 접근해야 할 때 두 개의 점 위치를 기록하면서 처리하는 알고리즘을 의미

### 구간 합(interval Sum) 문제
- 연속적으로 나열된 N개의 수가 있을 때 특정 구간의 모든 수를 합합 값을 계산하는 문제

## 재귀 함수(Recursive Function)
- 재귀 함수(Recursive Function)란 자기 자신을 다시 호출하는 함수
- 단순한 형태의 재귀 함수 예제
    - '재귀 함수를 호출합니다.'라는 문자열을 무한히 출력
    - 어느 정도 출력하다가 최대 재귀 깊이 초과 메세지가 출력
- 재귀 함수의 종료 조건
    - 재귀 함수를 문제 풀이에서 사용할 때는 재귀 함수의 종료 조건을 반드시 명시
    - 종료 조건을 제대로 명시하지 않으면 함수가 무한히 호출
        - 종료 조건을 포함한 재귀 함수 예제
```python
def recursive_function(i):
    # 100번째 호출을 했을 때 종료되도록 종료 조건 명시
    if i == 100:
        return
    print(i, '번째 재귀함수에서', i + 1, '번째 재귀함수를 호출합니다.')
    recursive_function( i + 1)
    print(i, '번째 재귀함수를 종료합니다.')

recursive_function(1)
```
### 최대공약수 계산 (유클리드 호제법)
- 두 개의 자연수에 대한 최대공약수를 구하는 대표적인 알고리즘으로는 유클리드 호제법이 있습니다.
- 유클리드 호제법
    - 두 자연수 A,B에 대하여 (A>B)A를 B로 나눈 나머지를 R이라고 한다.
    - 이때 A와 B의 최대공약수는 B와 R의 최대공약수와 같다.
- 유클리드 호제법의 아이디어를 그대로 재귀 함수로 작성할 수 있다.
- 
### 재귀 함수 사용의 유의사항
- 재귀 함수를 잘 활용하면 복잡한 알고리즘을 간결하게 작성
    - 단, 오히려 다른 사람이 이해하기 어려운 형태의 코드가 될 수도 있으므로 신중하게 사용
- 모든 재귀 함수는 반복문을 이용하여 동일한 기능을 구현할 수 있다
- 재귀 함수가 반복문보다 유리한 경우도 있고 불리한 경우도 있음
- 컴퓨터가 함수를 연속적으로 호출하면 컴퓨터 메모리 내부의 스택 프레임에 쌓인다.
    - 그래서 스택을 사용해야 할 때 구현상 스택 라이브러리 대신에 재귀 함수를 이용하는 경우가 많다
    - 
## 실전에서 유용한 표준 라이브러리
- 내장함수: 기본 입출력 함수부터 정렬 함수까지 기본적인 함수들을 제공
    - 파이썬 프로그램을 작성할 때 없어서는 안되는 필수적인 기능 포함
- itertools: 파이썬에서 반복되는 형태의 데이터를 처리하기 위한 유용한 기능들을 제공
    - 특히 순열과 조합 라이브러리는 코딩 테스트에서 자주 사용
- heapq: 힙(Heap) 자료구조를 제공
    - 일반적으로 우선순위 큐 기능을 구현하기 위해 사용
- bisect: 이진 탐색(Binary Search) 기능을 제공
- Collections: 덱(deque), 카운터(Counter) 등의 유용한 자료구조를 포함
- math: 필수적인 수학적 기능을 제공
    - 팩토리얼, 제곱근, 최대공약수(GCD), 삼각함수 관련 함수부터 파이(pi)와 같은 상수를 포함

### 자주 사용되는 내장 함수
- sum()
- min(), max()
- eval()
- sorted()
- sorted() with key
- counter
- math 라이브러리 gcd(): 최대공약수
-               lcm(): 최소공배수

## 다이나믹 프로그래밍
- 메모리를 적절히 사용하여 수행 시간 효율성을 비약적으로 향상시키는 방법
- 이미 계산된 결과(작은 문제)는 별도의 메모리 영역에 저장하여 다시 계산하지 않도록 함
- 일반적으로 두 가지 방식(탑다운, 보텀업)으로 구성
- 동적 계획법이라고도 부름
- 다이나믹 프로그래밍 조건
    - 최적 부분 구조(Optimal Substructure)
        - 큰 문제를 작은 문제로 나눌 수 있으며, 작은 문제의 답을 모아서 큰 문제 해결
    - 중복되는 부분 문제(Overlapping Subproblem)
        - 동일한 작은 문제를 반복적으로 해결
- 피보나치 수열의 시간 복잡도
    - 세타 표기법
    - 빅오 표기법
### 메모이제이션(Memoization)
- 다이나믹 프로그래밍을 구현하는 방법 중 하나
- 한 번 계산된 결과를 메모리 공간에 메모하는 기법
    - 같은 문제를 다시 호출하면 메모했던 결과를 그대로 가져옴
    - 값을 기록해 놓는다는 점에서 캐싱(Caching)이라고도 함
- 이전에 계산된 결과를 일시적으로 기록해 놓는 넓은 개념을 의미
- 메모이제이션을 사용하는 경우 피보나치 수열 함수의 시간 복잡도는 O(N)
### 탑다운 vs 보텀업
- 탑다운(메모이제이션) 방식은 하향식이라고도 함
- 보텀업 방식은 상향식이라고도 함
- 다이나믹 프로그래밍의 전형적인 형태는 보텀업 방식

### 다이나믹 프로그래밍 vs 분할 정복
- 모두 최적 부분 구조를 가질 때 사용
    - 큰 문제를 작은 문제로 나눌 수 있음
- 차이점은 부분 문제의 중복
    - 다이나믹 프로그래밍 문제에서는 각 부분 문제들이 서로 영향을 미치며 부분 문제가 중복
    - 분할 정복 문제에서는 동일한 부분 문제가 반복적으로 계산되지 않음
